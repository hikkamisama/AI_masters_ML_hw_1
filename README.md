## Первая домашка по МО

### Бейзлайн

Была обучена линейная регрессия на вещественных признаках со стандартными параметрами

```
R2 train: 0.5106748311347167, R2 test: 0.5337619219828837
MSE train: 140259353320.23706, MSE test: 268006960970.22333
RMSE train: 374512.1537683885, RMSE test: 517693.88732167135
```

### Стандартизация

Стандартизация не помогла ни в улучшении предсказаний, ни в уменьшении модуля весов

### L1 Регуляризация

Был подобран по сетке гиперпараметр регуляризации, однако улучшить предсказание сильно не удалось

```
MSE test: 268006960973.5476
```

### ElasticNet

Были подобраны по сетке два гиперпараметра - коэффициент L1 регуляризации и доля участия L1 регуляризации, улучшить предсказание не удалось

```
MSE test: 268392823624.51144
```

### L0 регуляризация

Были подобраны лучшие признаки при ограничении на количество признаков. Лучше всего было оставить два признака - `max_power_float` и `mileage_float`

```
R2 train: 0.5070630660952546, R2 test: 0.5385954819021317
MSE train: 141294623649.6876, MSE test: 265228492703.25006
RMSE train: 375891.77119177213, RMSE test: 515003.3909628655
```

### Добавление категориальных признаков

Категориальные признаки были закодированы с помощью OHE, была обучена ridge-регрессия и подобран параметр регуляризации. Это сработало лучше всего.

```
R2 train: 0.7099787983332719, R2 test: 0.7432550861418853
MSE train: 83131195334.30847, MSE test: 147584308000.5769
RMSE train: 288324.80873887433, RMSE test: 384167.0313816334
```

### Попытка почистить датасет

Подумала что будет полезно удалить аномалии по таргету и некоторым признакам, но так как выбросы есть и в тесте, а основная метрика у нас mse, к улучшению результатов это не привело

### Добавление нелинейных признаков

Реализовала преобразование признаков, получающее квадрат, обратную функцию, логарифм и попарные перемножения. Обучила ridge и подобрала параметры, итоговые результаты (модель сохранена в linear_model.pkl):

```
R2 train: 0.8949808646544214, R2 test: 0.8819209015575816
MSE train: 30102510451.238655, MSE test: 67875237608.74505
RMSE train: 173500.75057831494, RMSE test: 260528.76541515536
```